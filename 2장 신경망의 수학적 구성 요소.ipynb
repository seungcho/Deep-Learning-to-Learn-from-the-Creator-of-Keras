{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1 신경망과의 첫 만남**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 지금 풀려는 문제는 흑백 손글씨 숫자 이미지(28X28)를 10개의 범주(0~9)로 분류하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 머신 러닝에서 분류 문제의 범주(category)를 클래스(class)라 한다. 데이터 포인트는 샘플(sample)이라 한다. 특정 샘플의 클래스는 레이블(label)이라한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 6s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape # 60,000개의 샘플과 28x28 = 564개의 feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_images) # 샘플 수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. 작업 순서는 다음과 같다. 먼저 훈련 데이터 train_images와 train_labels를 네트워크에 주입**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. 네트워크는 이미지와 레이블을 연관시킬 수 있도록 학습**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. 마지막으로 test_images에 대한 예측을 네트워크에 요청**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. 이 예측이 test_labels와 맞는지 확인**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = models.Sequential()\n",
    "network.add(layers.Dense(512,activation='relu',input_shape=(28*28,))) # \n",
    "network.add(layers.Dense(10,activation='softmax')) # 출력층 softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.compile(optimizer='rmsprop', # 최적화 rmse\n",
    "               loss = 'categorical_crossentropy', # cross_entropy\n",
    "               metrics = ['accuracy']) # accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape((60000,28*28)) # 이미지를 28X28 reshape\n",
    "train_images = train_images.astype('float32') / 255 # 0 ~ 1 scale 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = test_images.reshape((10000,28*28)) # 이미지를 28X28 reshape\n",
    "test_images = test_images.astype('float32') / 255 # 0 ~ 1 scale 조정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = to_categorical(train_labels) # label을 categorical(one-hot)으로 변경\n",
    "test_labels = to_categorical(test_labels) # label을 categorical(one-hot)으로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 1s 19us/step - loss: 0.2568 - accuracy: 0.9254\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.1033 - accuracy: 0.9695\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0687 - accuracy: 0.9796\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 1s 14us/step - loss: 0.0496 - accuracy: 0.9848\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 1s 13us/step - loss: 0.0373 - accuracy: 0.9889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1a90f427c18>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(train_images,train_labels,epochs=5,batch_size=128) # model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 57us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = network.evaluate(test_images,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_acc: 0.979\n"
     ]
    }
   ],
   "source": [
    "print('test_acc:',test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2 신경망을 위한 데이터 표현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서는 머신 러닝의 기본 구성요소\n",
    "\n",
    "> - **텐서라 부르는 다차원 넘파이 배열에 데이터를 저장한다.**\n",
    "\n",
    "> - 2D텐서: 행렬, 3D텐서는: 3차원 벡터 ,...,\n",
    "\n",
    "> - 텐서의 축 개수를 랭크(rank)라고도 부른다.\n",
    "\n",
    "**3D텐서**\n",
    "\n",
    "![test](./img/차원.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 위 그림 처럼 3D텐서는 3개의 축을 가진 것(텐서의 각 축을 따라 여러 개의 차원을 가진 벡터가 놓일 수 있다.)\n",
    "\n",
    "**2차원 벡터**\n",
    "![test](./img/벡터.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2차원 평면상의 점 P가 찍혀있다고 생각해보자. \n",
    "\n",
    "원점을 기준으로 했을때 하나의 선분이 점 P방향으로 X만큼 우측으로 이동하고 있고 Y만큼 상승하고 있다는 것을 알 수가 있다.\n",
    "\n",
    "이는 점 P가 원점을 기준으로한 방향을 가지고 있다고 볼 수 있다.\n",
    "\n",
    "그리고 하나의 점이 원점에서 부터 X만큼 Y만큼 크기를 가지고 이동하고 있다고 표현할수 있다.\n",
    "\n",
    "방향과 크기를 동시에 가지고 있다고 할 수 있다.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3차원 벡터**\n",
    "![test](./img/벡터1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그리고 2차원의 벡터에 Z축을 하나더 추가하면 3차원읠 벡터를 표시할 수 있다. \n",
    "\n",
    "이 벡터는 원점을 기준으로 X Y Z의 방향과 크기를 가지고 있다. \n",
    "\n",
    "즉, 하나의 축을 따라 3개의 차원을 가진 것\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([12,3,6,14,7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 첫번째 축에 놓여 있는 원소([1,2,3],[4,5,6])을 행\n",
    "# 두번째 축에 놓여 있는 원소([1,4],[2,5],[3,6])을 열\n",
    "x = np.array([[1,2,3],\n",
    "             [4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[[1,1,1,1,1],\n",
    "              [5,5,5,5,5],\n",
    "              [3,3,3,3,3]],\n",
    "             [[2,2,2,2,2],\n",
    "             [6,6,6,6,6],\n",
    "             [7,7,7,7,7]],\n",
    "             [[1,2,3,3,3],\n",
    "             [1,1,1,1,1],\n",
    "             [3,3,3,3,3]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 5)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **핵심 속성**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 축의 개수(랭크)  \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 크기(shape): 텐서의 각 축을 따라 얼마나 많은 차원이 있는지를 나타낸 파이썬의 튜플(tuple)이다.\n",
    "\n",
    "> - 벡터의 크기는 (5,)처럼 1개의 원소로 이루어진 튜플이다. 배열 스칼라는 ()처럼 크기가 의미가 없다.\n",
    "\n",
    "- 데이터 타입: 텐서에 포함된 데이터 타입으로 float32,uint8,float64 등이 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images,train_labels),(test_images,test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uint8\n"
     ]
    }
   ],
   "source": [
    "print(train_images.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit = train_images[4]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(digit, cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2.1 넘파이로 텐서 조작하기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 배열에 있는 특정 원소들을 선택하는 것을 슬라이싱(slicing)이라 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slice = train_images[10:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slice = train_images[10:100,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_slice = train_images[10:100,0:28,0:28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 28, 28)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_slice.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2.2 텐서의 실제 사례**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 벡터 데이터: (sample,feature) 크기의 2D 텐서\n",
    "\n",
    "> - 일반적인 구조적 데이터셋에서 주로 사용\n",
    "\n",
    "> - 여기서 첫 번째 축은 샘플 축이고, 두 번째 축은 특성 축 이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 시계열 또는 시퀸스 데이터: (sample,timesteps,feature) 크기의 3D텐서\n",
    "\n",
    "> - 데이터에서 시간이 중요할 때는 시간 축을 포함하여 3D 텐서로 저장된다.\n",
    "\n",
    "> - 각 샘플은 벡터의 시퀀스로 인코딩되므로 배치 데이터는 3D 텐서로 인코딩될 것이다.\n",
    "\n",
    "> - 주식 가격 데이터셋: 1분마다 현재 주식 가격, 지난 1분 동안에 최고 가격과 최소 가격을 저장 1분마다 데이터는 3D 벡터로 인코딩되고 하루 동안의 거래는 (390,3) 크기의 2D 텐서로 저장 (하루의 거래 시간은 390분이다.) 여기서 1일치 데이터가 하나의 샘플이 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이미지: (sample,height,width,channels) 또는 (sample,channels,height,width)크기의 4D텐서\n",
    "\n",
    "> - 이미지는 전형적으로 높이,너비,컬러 채널의 3차원으로 이루어진다. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 동영상: (sample,frames,height,width,channels) 또는 (samples,frames,channels,height,width) 크기의 5D텐서\n",
    "\n",
    "> - 비디오 데이터는 현실에서 5D 텐서가 필요한 몇 안 되는 데이터 중 하나이다.\n",
    "\n",
    "> - 하나의 비디오는 프레임의 연속이고 각 프레임은 하나의 컬러 이미지이다.\n",
    "\n",
    "> - 프레임의 연속은 (sample,frames,height,width,color_depth)의 5D로 저장\n",
    "\n",
    "> - 예를들어 60초짜리 144X256 유튜브 비디오 클립을 초당 4프레임으로 샘플링하면 240프레임이 된다.  이런 비디오 클립을 4개 가진 배치는 (4,240,144,256,3)크기의 텐서에 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3 신경망의 톱니바퀴: 텐서 연산**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 심층 신경망이 학습한 모든 변환을 수치 데이터 텐서에 적용하는 몇 종류의 텐서 연산으로 나타낼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3.1 원소별 연산**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- relu 함수와 덧셈은 원소별 연산이다. **즉, 이 연산은 텐서에 있는 각 원소에 독립적으로 적용됩니다.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_relu(x):\n",
    "    assert len(x.shape) == 2 # 차원을 반환 / X가 2D가 아닌 경우 오류 출력\n",
    "    \n",
    "    x = x.copy() # 입력 텐서 자체를 바꾸지 않도록 복사\n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] = max(x[i,j],0) # 행렬의 각 원소와 0을 비교하여 최대값 반환\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_add(x,y):\n",
    "    assert len(x.shape) == 2\n",
    "    assert x.shape == y.shape # 행렬의 덧셈은 shape이 같아야함\n",
    "    \n",
    "    x = x.copy()\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            x[i,j] += y[i,j]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **넘파이는 시스템에 설치된 BLAS 구현에 복잡한 일들을 위임한다. 따라서 넘파이 배열을 다룰 때는 넘파이 내장 함수로 이런 연산들을 쉽게 처리할 수 있다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,-2,3],[-4,5,6]])\n",
    "y = np.array([[1,-1,1],[-1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 0., 4.],\n",
       "       [0., 6., 7.]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.maximum(z,0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3.2 브로드 캐스팅**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **브로드캐스팅**\n",
    "\n",
    "> - 큰 텐서의 ndim에 맞도록 작은 텐서에 (브로드케스팅 축이라고 부르는) 축이 추가된다.\n",
    "\n",
    "> - 작은 텐서가 새 축을 따라서 큰 텐서의 크기에 맞도록 반복된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((64,3,32,10))\n",
    "y = np.random.random((32,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.maximum(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3, 32, 10)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3.3 텐서 점곱**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서 곱셈(행렬의 곱)이라고도 부르는 점곱 연산은 가장 널리 사용되고 유용한 텐서 연산이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3],[3,3,3]])\n",
    "y = np.array([[3,3],\n",
    "             [2,2,],\n",
    "             [1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 10],\n",
       "       [18, 18]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3])\n",
    "y = np.array([2,2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3.4 텐서 크기 변환**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 꼭 알아 두어야 할 세 번째 텐서 연산은 텐서 크기 변환이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 텐서의 크기를 변환한다는 것은 특정 크기에 맞게 열과 행을 재배열한다는 뜻이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([[1,2,3],[4,5,6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2],\n",
       "       [3, 4],\n",
       "       [5, 6]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(3,2) # Transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1, 2, 3]],\n",
       "\n",
       "       [[4, 5, 6]]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.reshape(2,1,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3.6 딥러닝의 기하학적 해석**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 신경망은 전체적으로 텐서 연산의 연결로 구성된 것이고, 모든 텐서 연산은 입력 데이터의 기하학적 변환이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 단순한 단계들이 길게 이어져 구현된 신경망을 고차원 공간에서 매우 복잡한 기하학적 변환을 하는 것으로 해석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 신경망이 해야 할 일은 여러 이미지로 섞인 이미지들을 각각의 클래스에 맞게 깔끔하게 분리되도록 변환을 찾는 것이다.\n",
    "\n",
    "> - 즉, 종이를 펼치는 일이 머신러닝이 하는 일이다. (복잡하고 심하게 꼬여 있는 데이터의 매니폴드에 대한 깔끔한 표현을 찾는 일\n",
    "\n",
    "> - 기초적인 연산을 길게 연결하여 복잡한 기하학적 변환을 조금씩 분해하는 방식이 마치 사람이 종이 공을 펼치기 위한 전략과 매우 흡사하다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4 신경망의 엔진: 그래디언트 기반 최적화**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **가중치 또는 훈련되는 파라미터라고 부른다.(각각 커널과 편향이라고 부르기도 한다.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이런 가중치에는 훈련 데이터를 신경망에 노출시켜서 학습된 정보가 담겨 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 초기에는 가중치 행렬이 작은 난수로 채워져 있다.(무작위 초기화 단계라고 부름)\n",
    "\n",
    "> - **초기단계에서 유용한 표현을 기대하긴 어렵지만 그 다음에는 피드백 신호에 기초하여 가중치가 점진적으로 조정될 것이다.**\n",
    "\n",
    "> - **이런 점진적인 조정 또는 훈련이 머신 러닝 학습의 핵심이다.**\n",
    "\n",
    "- **훈련 반복 루프**\n",
    "\n",
    "> **1. 훈련 샘플 x와 이에 사응하는 타깃 y의 배치를 추출**\n",
    "\n",
    "> **2. x를 사용하여 네트워크를 실행하고(순전파 단계), 예측 y_pred를 구한다.**\n",
    "\n",
    "> **3. y_pred와 y의 차이를 측정하여 이 배치에 대한 네트워크의 손실을 계산**\n",
    "\n",
    "> **4. 배치에 대한 손실이 조금 감소되도록 네트워크의 모든 가중치를 업데이트한다.**\n",
    "\n",
    "- **결국 훈련 데이터에서 네트워크의 손실, 즉 예측 y_pred와 타깃 y의 오차가 매우 작아질 것이다.**\n",
    "\n",
    "> - **4가지의 단계중 가장 어려운 단계는 네트워크의 가중치를 업데이트하는 4단계이다.**\n",
    "\n",
    "> - **신경망에 사용된 모든 연산이 미분 가능 하다는 장점을 사용하여 네트워크 가중치에 대한 손실의 그래디언트를 계산하는 것이 가장 좋은 방법이다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4.1 변화율이란?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f(x) = y를 생각해보면 이 함수는 연속적이므로 x를 조금 바꾸면 y가 조금만 변경될 것이다. 이것이 연속성 개념\n",
    "\n",
    "> - 즉, f(x+epsilon_x) = y + epsilon_y\n",
    "\n",
    "- epsilon_x가 충분히 작다면 어떤 포인트 p에서 기울기 a의 선형 함수로 f를 근사할 수 있다.\n",
    "\n",
    "> - 따라서 f(x+epsilon_x) = y + a * epsilon_x\n",
    "\n",
    "> - 이 선형적인 근사는 x가 p에 충분히 가까울 때 유효하다.\n",
    "\n",
    "> - 이 기울기를 p에서 f의 변화율이라 한다. \n",
    "\n",
    "> - a의 절대값(변화율의 크기)은 이런 증가나 감소가 얼마나 빠르게 일어날지 알려준다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **모든 미분 가능한(미분 가능하다는 것은 변화율을 유도할 수 있다는 의미로, 예를 들어 매끄럽고 연속적인 함수이다.) 함수 f(x)에 대해 x의 값을 f의 국부적인 선형 근사인 그 지점의 기울기로 매핑하는 변화율 함수 f'(x)가 존재**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **f(x)를 최소화하기 위해 epsilon_x만큼 x를 업데이트하고 싶을 때 f의 변화율을 알고 있으면 해결된다.**\n",
    "\n",
    "> - **변화율 함수는 x가 바뀜에 따라 f(x)가 어떻게 바뀔지 설명해 준다. f(x)의 값을 감소 시키고 싶다면 x를 변화율의 방향과 반대로 조금 이동해야 한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4.2 텐서 연산의 변화율: 그래디언트**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 그래디언트는 텐서 연산의 변화율이다. 이는 다차원 입력, 즉 텐서를 입력으로 받는 함수에 변화율 개념을 확장시킨 것이다.\n",
    "\n",
    "> - W의 현재 값을 W0라고 가정하면 포인트 W0에서 f의 변화율은 W와 같은 크기의 텐서인 gradient(f)(W0)이다. 이 텐서의 각 원소 gradient(f)(W0)[i,j]는 W0[i,j]를 변경했을 때 loss_value가 바뀌는 방향과 크기를 나타낸다.\n",
    "\n",
    "> - gradient(f)(W0)는 W0에서 f(W)의 기울기를 나타내는 텐서로 해석할 수 있다.\n",
    "\n",
    "> - 따라서 함수 f(W)의 입장에서는 그래디언트의 반대 방향으로 W를 움직이면 f(W)의 값을 줄일 수 있다. 예를들어 W1 = W0 - step * gradient(f)(W0)\n",
    "\n",
    "> - 이 말은 기울기가 작아지는 곡면의 낮은 위치로 이동된다는 의미이다. \n",
    "\n",
    "> - step은 W0에서 너무 크게 벗어나지 않기 위해 스케일링 비율을 뜻함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4.3 확률적 경사 하강법**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **함수의 최솟값은 변화율이 0인 지점이다. 따라서 우리가 할 일은 변화율이 0이 되는 지점을 모두 찾고 이 중에서 어떤 포인트의 함수 값이 가장 작은지를 확인**\n",
    "\n",
    "> - 실제 신경망에서는 파라미터의 개수가 수천 개보다 적은 경우가 거의 없고 종종 수천만 개가 되기 때문에 해석적으로 해결하는 것이 어렵다.\n",
    "\n",
    "- **랜덤한 배치 데이터에서 현재 손실 값을 토대로 하여 조금씩 파라미터를 수정하는 것이다.**\n",
    "\n",
    "> - **1. 훈련 샘플 배치 x와 이에 사응하는 타깃 y를 추출**\n",
    "\n",
    "> - **2. x로 네트워크를 실행하고 예측 y_pred를 구한다.**\n",
    "\n",
    "> - **3. 이 배치에서 y_pred와 y 사이의 오차를 측정하여 네트워크의 손실을 계산**\n",
    "\n",
    "> - **4. 네트워크의 파라미터에 대한 손실 함수의 그래디언트를 계산(역방향 패스)**\n",
    "\n",
    "> - **5. 그래디언트의 반대 방향으로 파라미터를 조금씩 이동 예를들어 w-= step * gradient처럼 하면 배치에 대한 손실이 조금 감소**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **위 과정을 미니 배치 확률적 경사 하강법이다. 확률적이란 단어는 각 배치 데이터가 무작위로 선택된다는 의미이다.(확률적이란 것은 무작위 하다는 것의 과학적 표현이다.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/학습률.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **step 값을 적절히 고르는 것이 중요한데 이 값이 너무 작으면 곡선을 따라 내려가는 데 너무 많은 반복이 필요하고 지역 최솟값에 갇힐 수 있다. 반대로 step이 너무 크면 손시 함수 곡선에서 완전히 임의의 위치로 이동시킬 수 있다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **SGD**\n",
    "\n",
    "> - 각 배치 데이터가 무작위로 선택되어 학습을 하는 미니 배치 SGD\n",
    "\n",
    "> - 반복마다 하나의 샘플과 하나의 타깃을 뽑는 진정한 SGD\n",
    "\n",
    "> - 가용한 모든 데이터를 사용하여 반복을 실행하는 배치 SGD\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 실제로는 매우 고차원 공간에서 경사 하강법을 사용하게 되는데 신경망에 있는 각각의 가중치 값은 이 공간에서 하나의 독립된 차원이고 수만 또는 수백만 개가 될 수도 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/경사.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **신경망이 훈련되는 실제 과정을 시각화하기는 어렵다. 사람이 이해할 수 있도록 1,000,000차원의 공간을 표현하는 것은 불가능하기 때문**\n",
    "\n",
    "> - **따라서 저차원 표현으로 얻은 직관이 실전과 항상 맞지는 않는다는 것을 유념해야한다.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **또 업데이트할 다음 가중치를 계산할 때 현재 그래디언트 값만 보지 않고 이전에 업데이트된 가중치를 여러 가지 다른 방식으로 고려하는 SGD변종이 많이 있다.**\n",
    "\n",
    "> - 예를들어 모멘텀을 사용한 SGD, Adagrad, RMSProp등 이런 변종들을 모두 최적화 방법 또는 옵티마이저라 부른다.\n",
    "\n",
    "> - 특히 여러 변종들에서 사용하는 모멘텀 개념은 아주 중요하다. 모멘텀은 SGD에 있는 2개의 문제점인 수렴 속도와 지역 최솟값을 해결한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![test](./img/지역.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **이러한 지역 최솟값에 빠지지 않기 위해 모멘텀을 사용하여 이 문제를 피한다. 여기에서 최적화 과정을 손실 곡선 위로 작은 공을 굴리는 것으로 생각하면 쉽게 이해할 수 있다.**\n",
    "\n",
    "> - 모멘텀이 충분하면 공이 골짜기에 갇히지 않고 전역 최솟값에 도달할 것이다.\n",
    "\n",
    "> - 모멘텀은 현재 기울기 값(현재 가속도)뿐만 아니라 (과거의 가속도로 인한)현재 속도를 함께 고려하여 각 단계에서 공을 움직인다. 실전에 적용할 때는 현재 그래디언트 값뿐만 아니라 이전에 업데이트한 파라미터에 기초하여 파라미터 w를 업데이트한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4.4 변화율 연결: 역전파 알고리즘**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- f(g(x))' = f'(g(x)) * g'(x)를 사용하여 유도될 수 있다.\n",
    "\n",
    "> - 연쇄 법칙을 신경망의 그래디언트 계산에 적용하여 역전파(Backpropagation)알고리즘이 탄생하게 되었다.\n",
    "\n",
    "> - 역전파는 최종 손실 값에서부터 시작한다.\n",
    "\n",
    "> - 손실 값에 각 파라미터가 기여한 정도를 계산하기 위해 연쇄 법칙을 적용하여 최상위 층에서 하위층까지 거꾸로 진행\n",
    "\n",
    "- 최근에는 기호 미분이 가능한 최신 프레임워크를 사용하여 신경망을 구현한다. \n",
    "\n",
    "> - 이 말은 변화율이 알려진 연산들로 연결되어 있으면 (연쇄 법칙을 적용하여) 네트워크 파라미터와 그래디언트 값을 매핑하는 그래디언트 함수를 호출하는 것으로 단순화 할 수 있다.\n",
    "\n",
    "> - 기호 미분 덕택에 역전파 알고리즘을 직접 구현할 필요가 전혀 없고 정확한 역전파 공식을 유도하느라 시간과 노력을 소모하지 않아도 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.5 요약**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - 학습은 훈련 데이터 샘플과 드에 사응하는 타깃이 주어졌을 때 손실 함수를 최소화 하는 모델 파라미터의 조합을 찾는 것을 의미\n",
    "\n",
    "> - 데이터 샘플과 타깃의 배치를 랜덤하게 뽑고 이 배치에서 손실에 대한 파라미터의 그래디언트를 계산함으로써 학습이 진행된다. 네트워크의 파라미터는 그래디언트의 반대 방향으로 조금씩 움직인다.\n",
    "\n",
    "> - 전체 학습 과정은 신경망이 미분 가능한 텐서 연산으로 연결되어 있기 때문에 가능하다.\n",
    "\n",
    "> - 현재 파라미터와 배치 데이터를 그래디언트 값에 매핑해 주는 그래디언트 함수를 구성하기 위해 미분의 연쇄법칙을 사용\n",
    "\n",
    "> - 이어지는 장에서 자주 보게 될 두 가지 핵심 개념은 손실과 옵티마이저이다. 이 두가지는 데이터 주입하기 전에 정의되어야 한다.\n",
    "\n",
    "> - 손실은 훈련하는 동안 최소화해야 할 양이므로 해결하려는 문제의 성공을 측정하는 데 사용한다.\n",
    "\n",
    "> - 옵티마이저는 손실에 대한 그래디언트가 파라미터를 업데이트하는 정확한 방식을 정의한다. 예를들어 RMSProp 옵티마이저, 모멘텀을 사용한 SGD 등이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**설명수정**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
